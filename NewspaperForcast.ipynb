{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_collection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from pyquery import PyQuery as pq\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "url_max_page_code = 22000\n",
    "url_min_page_code = 10000\n",
    "max_date_time = datetime.strptime(\"2020-05-19\", '%Y-%m-%d').date()\n",
    "min_date_time = datetime.strptime(\"2017-10-27\", '%Y-%m-%d').date()\n",
    "url_head = 'https://news.cqu.edu.cn/newsv2/show-14-'\n",
    "_headers = {\n",
    "    \"Cookies\": \"UM_distinctid=16f183f0e656d-0c44a277e897db-7711a3e-144000-16f183f0e66d; \"\n",
    "               \"Hm_lvt_fbbe8c393836a313e189554e91805a69=1585301062,1585805916; \"\n",
    "               \"Hm_lvt_bb57c1f66ec2fc27e393f9615bad47e5=1589206619,1590718273,1590719672; \"\n",
    "               \"Hm_lpvt_bb57c1f66ec2fc27e393f9615bad47e5=1590720915\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/80.0.3987.106 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "#  检查html文档是否是新闻html\n",
    "def not_exist(text):\n",
    "    doc = pq(text)\n",
    "    head_title = doc('h5').text()\n",
    "    if head_title == '提示信息':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# 检查文章的发布日期有没有在指定日期内\n",
    "def not_within_date(text_date):\n",
    "    date = datetime.strptime(text_date, '%Y-%m-%d').date()\n",
    "    if (date > max_date_time) or (date < min_date_time):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# 获取对应url的html文档\n",
    "def get_web_page(url):\n",
    "    request_source = rq.get(url, headers=_headers)\n",
    "    return request_source.text\n",
    "\n",
    "\n",
    "# 获取全部文章的url\n",
    "def get_all_url(start_code, end_code):\n",
    "    all_the_url = []\n",
    "    for i in range(start_code, end_code + 1):\n",
    "        url_realistic = url_head + str(i) + '-1.html'\n",
    "        all_the_url.append(url_realistic)\n",
    "    return all_the_url\n",
    "\n",
    "\n",
    "# 获取文章的属性信息\n",
    "def get_article(page):\n",
    "    if not_exist(page):\n",
    "        return None\n",
    "    document = pq(page)\n",
    "\n",
    "    # get date\n",
    "    date_text = document(\".ibox span\").text()\n",
    "    date_str = date_text.split(\":\")\n",
    "    date = date_str[1].strip()\n",
    "    # if the date is out of the limitation\n",
    "    if not_within_date(date):\n",
    "        return None\n",
    "\n",
    "    article_elements = []\n",
    "    # get title\n",
    "    title = document('h1').text()\n",
    "\n",
    "    # get writer\n",
    "    writer = \"无名氏\"\n",
    "    writer_nodes = document(\".dinfoa\")\n",
    "    if writer_nodes.find(\"span\").text() == \"作者 :\":\n",
    "        writer = writer_nodes.find(\"a\").text()\n",
    "\n",
    "    # get tags\n",
    "    tag_nodes = document(\".tags\")\n",
    "    tags = \"Nothing\"\n",
    "    if tag_nodes.find(\"span\").text() == \"相关热词搜索 :\":\n",
    "        tags = tag_nodes.find(\"a\").text()\n",
    "        if str.find(tags, \"，\") != -1:\n",
    "            tags = tags.replace(\"，\", \" \")\n",
    "        if str.find(tags, \";\"):\n",
    "            tags = tags.replace(\";\", \" \")\n",
    "\n",
    "    # get hits\n",
    "    hits_link = document(\"script[language=JavaScript]\").attr.src\n",
    "    data_text = rq.get(hits_link, headers=_headers).text\n",
    "    hits = re.findall(\"[0-9]+\", data_text)[-1]\n",
    "\n",
    "    article_elements.append(title)\n",
    "    article_elements.append(writer)\n",
    "    article_elements.append(date)\n",
    "    article_elements.append(tags)\n",
    "    article_elements.append(hits)\n",
    "\n",
    "    return article_elements\n",
    "\n",
    "\n",
    "# 将文章的属性信息存储下来\n",
    "def store_in_csv(file_name):\n",
    "    csv_file = open(file_name, \"w\", newline='', encoding='utf-8-sig')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"title\", \"writer\", \"date\", \"tags\", \"hits\"])\n",
    "    all_the_urls = get_all_url(url_min_page_code, url_max_page_code)\n",
    "    print(all_the_urls)\n",
    "    for url_item in all_the_urls:\n",
    "        web_page_text = get_web_page(url_item)\n",
    "        classify_article = get_article(web_page_text)\n",
    "        if classify_article is None:\n",
    "            continue\n",
    "        writer.writerow(classify_article)\n",
    "\n",
    "\n",
    "store_in_csv('raw_news_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visual_date.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "news_csv = pd.read_csv('raw_news_data.csv')\n",
    "\n",
    "\n",
    "# assign everyday's hits to\n",
    "def assign_hits_to_date(test_news):\n",
    "    date_with_hits = {}\n",
    "    for itemx in test_news.itertuples():\n",
    "        date = getattr(itemx, 'date')\n",
    "        hits = getattr(itemx, 'hits')\n",
    "\n",
    "        if date_with_hits.get(date, 0) == 0:\n",
    "            date_with_hits[date] = [[hits], 0]\n",
    "        else:\n",
    "            date_with_hits[date][0].append(hits)\n",
    "    return date_with_hits\n",
    "\n",
    "\n",
    "date_with_hits = assign_hits_to_date(news_csv)\n",
    "\n",
    "\n",
    "# fill the dict with the delfault date\n",
    "def fill_date_with_hits(start='2017-10-27', end='2020-05-19'):\n",
    "    start_date = dt.strptime(start, '%Y-%m-%d').date()\n",
    "    end_date = dt.strptime(end, '%Y-%m-%d').date()\n",
    "    cur_date = start_date\n",
    "    while (cur_date <= end_date):\n",
    "        date = str(cur_date)\n",
    "        if date_with_hits.get(date, 0) == 0:\n",
    "            date_with_hits[date] = [[0], 0]\n",
    "        cur_date += datetime.timedelta(days=1)\n",
    "\n",
    "\n",
    "fill_date_with_hits()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# compute the average\n",
    "for key, value in date_with_hits.items():\n",
    "    average_hits = int(0.5 + np.mean(value[0]))\n",
    "    date_with_hits[key][1] = average_hits\n",
    "\n",
    "# sort the dict by the key\n",
    "sorted_date_with_hits = sorted(date_with_hits.items(), key=lambda item: item[0], reverse=False)\n",
    "\n",
    "\n",
    "def plot_by_year(start_time, end_time):\n",
    "    lenth_of_x = 0\n",
    "    y = []\n",
    "    # plot the line\n",
    "    for item in sorted_date_with_hits:\n",
    "        if (item[0] >= start_time) and (item[0] <= end_time):\n",
    "            lenth_of_x += 1\n",
    "            y.append(item[1][1])\n",
    "    x = range(0, lenth_of_x)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(x, y)\n",
    "    plt.scatter(x, y, marker='o', color='m', label='hits', s=20)\n",
    "    plt.title(start_time + ' to ' + end_time)\n",
    "    plt.legend()\n",
    "\n",
    "    # plot the month number\n",
    "    start = dt.strptime(start_time, '%Y-%m-%d').date()\n",
    "    cur = start\n",
    "    last_month = cur.month\n",
    "    sig_12 = False\n",
    "    for i in range(len(x)):\n",
    "        cur = start + datetime.timedelta(days=x[i])\n",
    "        cur_month = cur.month\n",
    "        if (cur_month > last_month and not sig_12) or (cur_month < last_month):\n",
    "            plt.annotate(str(cur_month), (x[i], 0), color='black', fontsize=20,\n",
    "                         arrowprops=dict(facecolor='r', shrink=0.05))\n",
    "            last_month = cur_month\n",
    "            if last_month == 12:\n",
    "                sig_12 = True\n",
    "            else:\n",
    "                sig_12 = False\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_by_year('2017-10-27', '2018-02-28')\n",
    "\n",
    "plot_by_year('2018-03-01', '2018-08-31')\n",
    "\n",
    "plot_by_year('2018-09-01', '2019-02-28')\n",
    "\n",
    "plot_by_year('2019-03-01', '2019-08-31')\n",
    "\n",
    "plot_by_year('2019-09-01', '2020-02-29')\n",
    "\n",
    "plot_by_year('2020-03-01', '2020-05-19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count_tags.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 加载并分割数据\n",
    "articles = pd.read_csv(\"raw_news_data.csv\")\n",
    "tags_and_hits = articles[[\"tags\", \"hits\"]]\n",
    "# 得到条目数量\n",
    "length = len(tags_and_hits)\n",
    "\n",
    "tag_hit_list = []\n",
    "for i in range(0, length):\n",
    "    # 去除标签中的脏字符\n",
    "    tag_str = tags_and_hits.iloc[i][\"tags\"]\n",
    "    tag_str = tag_str.replace(\"\\\"\", \"\")\n",
    "    tag_str = tag_str.replace(\"“\", \"\")\n",
    "    tag_str = tag_str.replace(\"”\", \"\")\n",
    "    tag_str = tag_str.replace(\"、\", \" \")\n",
    "    tag_str = tag_str.replace(\";\", \" \")\n",
    "    # 将标签字符串分割\n",
    "    tags = tag_str.split()\n",
    "    # 记录下该标签字符串对应的点击量\n",
    "    h = tags_and_hits.iloc[i][\"hits\"]\n",
    "    for tag in tags:\n",
    "        #  去除只有一个字符的标签\n",
    "        if len(tag) > 1:\n",
    "            # 存储标签与其对应的点击量\n",
    "            tag_hit_list.append((tag, h))\n",
    "# 按标签排序\n",
    "tag_hit_list.sort()\n",
    "\n",
    "length = len(tag_hit_list)\n",
    "i = 0\n",
    "tag_hit_u_list = []\n",
    "while i < length:\n",
    "    hit_sum = tag_hit_list[i][1]\n",
    "    # 检查前后两个相同的标签并求和其点击量\n",
    "    while i < length-1 and tag_hit_list[i][0] == tag_hit_list[i + 1][0]:\n",
    "        hit_sum += tag_hit_list[i + 1][1]\n",
    "        i += 1\n",
    "    # 将结果存储在tag_hit_u_list中\n",
    "    tag_hit_u_list.append((tag_hit_list[i][0],hit_sum))\n",
    "    i += 1\n",
    "\n",
    "length = len(tag_hit_u_list)\n",
    "tag_list = []\n",
    "hit_list = []\n",
    "\n",
    "# 构建DataFrame\n",
    "for i in range(0,length):\n",
    "    tag_list.append(tag_hit_u_list[i][0])\n",
    "    hit_list.append(tag_hit_u_list[i][1])\n",
    "tag_hit_dic = {\n",
    "    # 绘制前50个关键词\n",
    "    \"tags\":tag_list[0:50],\n",
    "    \"hits\":hit_list[0:50]\n",
    "}\n",
    "tag_hit_df = pd.DataFrame(tag_hit_dic)\n",
    "# 按点击量排序\n",
    "tag_hit_df = tag_hit_df.sort_values(by=\"hits\")\n",
    "print(tag_hit_df)\n",
    "\n",
    "tag_hit_df.plot.bar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count_writer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "articles = pd.read_csv(\"raw_news_data.csv\")\n",
    "writers_and_hits = articles[[\"writer\", \"hits\"]]\n",
    "length = len(writers_and_hits)\n",
    "\n",
    "writer_hit_list = []\n",
    "for i in range(0, length):\n",
    "    writer_str = writers_and_hits.iloc[i][\"writer\"]\n",
    "    writer_str = writer_str.replace(\"、\", \" \")\n",
    "    writer = writer_str.split()[0]\n",
    "    h = writers_and_hits.iloc[i][\"hits\"]\n",
    "    writer_hit_list.append((writer, h))\n",
    "writer_hit_list.sort()\n",
    "\n",
    "length = len(writer_hit_list)\n",
    "i = 0\n",
    "writer_hit_u_list = []\n",
    "while i < length:\n",
    "    hit_sum = writer_hit_list[i][1]\n",
    "    while i<length-1 and writer_hit_list[i][0] == writer_hit_list[i + 1][0]:\n",
    "        hit_sum += writer_hit_list[i + 1][1]\n",
    "        i += 1\n",
    "    writer_hit_u_list.append((writer_hit_list[i][0],hit_sum))\n",
    "    i += 1\n",
    "\n",
    "length = len(writer_hit_u_list)\n",
    "writer_list = []\n",
    "hit_list = []\n",
    "for i in range(0,length):\n",
    "    writer_list.append(writer_hit_u_list[i][0])\n",
    "    hit_list.append(writer_hit_u_list[i][1])\n",
    "tag_hit_dic = {\n",
    "    \"tags\":writer_list[0:50],\n",
    "    \"hits\":hit_list[0:50]\n",
    "}\n",
    "writer_hit_df = pd.DataFrame(tag_hit_dic)\n",
    "writer_hit_df = writer_hit_df.sort_values(by=\"hits\")\n",
    "print(writer_hit_df)\n",
    "\n",
    "writer_hit_df.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}